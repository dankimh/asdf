{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "116567ed",
      "metadata": {
        "id": "116567ed"
      },
      "source": [
        "\n",
        "# Zero/Few-shot In-context Learning 실습 노트북\n",
        "**작성일**: 2025-07-18 by Yeongtak Oh (Credit : DSAIL LAb, SNU)\n",
        "\n",
        "**목표**:  \n",
        "- Zero-shot 및 Few-shot 학습 방식 이해  \n",
        "- Chain-of-Thought 및 Tool-use 프롬프트 실습  \n",
        "- 사용자 입력 기반 인터랙션 실습  \n",
        "- 결과 CSV 저장, 체크리스트, 퀴즈 포함\n",
        "\n",
        "---\n",
        "> 본 노트북은 HD현대 실습을 위해 교육용 자료로서 준비되었으며, PyTorch와 HuggingFace Transformers 라이브러리를 사용합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e695b355",
      "metadata": {
        "id": "e695b355"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets ipywidgets --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e94f83d",
      "metadata": {
        "id": "9e94f83d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import os\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        " # https://huggingface.co/gpt2-medium\n",
        "model_name = \"gpt2-medium\" # \"Qwen/Qwen3-0.6B\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
        "model.eval()\n",
        "\n",
        "log = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "433ba523",
      "metadata": {
        "id": "433ba523"
      },
      "outputs": [],
      "source": [
        "def generate_completion(prompt, max_new_tokens=50):\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(\n",
        "            input_ids,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            top_p=0.95,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "    output = tokenizer.decode(output_ids[0][input_ids.shape[-1]:], skip_special_tokens=True)\n",
        "    log.append({\"prompt\": prompt, \"response\": output})\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91e63227",
      "metadata": {
        "id": "91e63227"
      },
      "source": [
        "\n",
        "## 실습 체크리스트\n",
        "\n",
        "- 1) Zero-shot 번역 실습 실행  \n",
        "- 2) Few-shot 번역 실습 실행  \n",
        "- 3) 감정 분석 예제 실행  \n",
        "- 4) 사용자 직접 프롬프트 실습  \n",
        "- 5) Chain-of-Thought 예제 실행  \n",
        "- 6) Tool-use 예제 실행  \n",
        "- 결과를 CSV로 저장\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41a96587",
      "metadata": {
        "id": "41a96587"
      },
      "outputs": [],
      "source": [
        "# zero-shot은 demonstration x\n",
        "print(\"Zero-shot 예제\")\n",
        "prompt = \"Translate English to French: I like pizza.\"\n",
        "print(\"Prompt:\", prompt)\n",
        "print(\"Generated:\", generate_completion(prompt))\n",
        "\n",
        "# few-shot은 demonstration o\n",
        "print(\"\\n Few-shot 예제\")\n",
        "few_shot = (\n",
        "    \"Translate English to French:\\n\"\n",
        "    \"English: Hello.\\nFrench: Bonjour.\\n\"\n",
        "    \"English: Good night.\\nFrench: Bonne nuit.\\n\"\n",
        "    \"English: I like pizza.\\nFrench:\"\n",
        ")\n",
        "print(\"Prompt:\\n\", few_shot)\n",
        "print(\"Generated:\", generate_completion(few_shot))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48b63c07",
      "metadata": {
        "id": "48b63c07"
      },
      "outputs": [],
      "source": [
        "# example 1: sentimental analysis\n",
        "print(\"\\n 감정 분석 Few-shot\")\n",
        "emotion_prompt = (\n",
        "    \"Tweet: I hate everything.\\nSentiment: Negative\\n\"\n",
        "    \"Tweet: I love sunshine.\\nSentiment: Positive\\n\"\n",
        "    \"Tweet: I want to cry.\\nSentiment:\"\n",
        ")\n",
        "print(generate_completion(emotion_prompt))\n",
        "\n",
        "# CoT example\n",
        "print(\"\\n Chain-of-Thought 예제\")\n",
        "cot = (\n",
        "    \"Q: If a train has 5 cars and each car has 20 people, how many total people?\\n\"\n",
        "    \"A: Let's think step by step. Each car has 20 people. There are 5 cars. So 5 * 20 = 100. Answer: 100\"\n",
        "    \"\\n\\nQ: There are 3 boxes. Each box has 4 apples. How many apples?\\nA:\"\n",
        ")\n",
        "print(generate_completion(cot))\n",
        "\n",
        "# Tool use example\n",
        "print(\"\\n Tool-use 예제\")\n",
        "tool_prompt = (\n",
        "    \"Question: What is 15 * 12?\\n\"\n",
        "    \"Let's use a calculator: 15 * 12 = 180.\\nAnswer: 180\\n\"\n",
        "    \"Question: What is 9 * 11?\\nLet's use a calculator:\"\n",
        ")\n",
        "print(generate_completion(tool_prompt))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73b0bec8",
      "metadata": {
        "id": "73b0bec8"
      },
      "outputs": [],
      "source": [
        "# With on your own prompts (PLAYGROUND)\n",
        "prompt_input = widgets.Textarea(\n",
        "    value='Input your prompt here...',\n",
        "    placeholder='Enter any instruction or query',\n",
        "    description='Prompt:',\n",
        "    layout=widgets.Layout(width='100%', height='100px')\n",
        ")\n",
        "button = widgets.Button(description='Generate')\n",
        "output = widgets.Output()\n",
        "\n",
        "@output.capture()\n",
        "def on_click(b):\n",
        "    output.clear_output()\n",
        "    prompt = prompt_input.value\n",
        "    result = generate_completion(prompt)\n",
        "    print(\"Generated:\", result)\n",
        "\n",
        "button.on_click(on_click)\n",
        "display(prompt_input, button, output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c78dc4c",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3c78dc4c"
      },
      "outputs": [],
      "source": [
        "# Output save files\n",
        "df = pd.DataFrame(log)\n",
        "df.to_csv(\"incontext_outputs.csv\", index=False)\n",
        "print(\"💾 Saved as incontext_outputs.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c40e4182",
      "metadata": {
        "id": "c40e4182"
      },
      "source": [
        "\n",
        "## 📝 퀴즈 (5분)\n",
        "\n",
        "1. Zero-shot learning과 Few-shot learning의 차이를 서술하시오.  \n",
        "2. Chain-of-Thought prompting이 모델 성능 향상에 어떤 영향을 미치는가?  \n",
        "3. Tool-use prompting의 한계점은 무엇인가?\n",
        "\n",
        "> 답안은 아래 셀에 작성하세요.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaeac057",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eaeac057"
      },
      "outputs": [],
      "source": [
        "# 여기에 작성하세요.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BPmggjzZXVmn",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BPmggjzZXVmn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}