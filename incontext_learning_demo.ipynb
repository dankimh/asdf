{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "116567ed",
      "metadata": {
        "id": "116567ed"
      },
      "source": [
        "\n",
        "# Zero/Few-shot In-context Learning ì‹¤ìŠµ ë…¸íŠ¸ë¶\n",
        "**ì‘ì„±ì¼**: 2025-07-18 by Yeongtak Oh (Credit : DSAIL LAb, SNU)\n",
        "\n",
        "**ëª©í‘œ**:  \n",
        "- Zero-shot ë° Few-shot í•™ìŠµ ë°©ì‹ ì´í•´  \n",
        "- Chain-of-Thought ë° Tool-use í”„ë¡¬í”„íŠ¸ ì‹¤ìŠµ  \n",
        "- ì‚¬ìš©ì ì…ë ¥ ê¸°ë°˜ ì¸í„°ë™ì…˜ ì‹¤ìŠµ  \n",
        "- ê²°ê³¼ CSV ì €ì¥, ì²´í¬ë¦¬ìŠ¤íŠ¸, í€´ì¦ˆ í¬í•¨\n",
        "\n",
        "---\n",
        "> ë³¸ ë…¸íŠ¸ë¶ì€ HDí˜„ëŒ€ ì‹¤ìŠµì„ ìœ„í•´ êµìœ¡ìš© ìë£Œë¡œì„œ ì¤€ë¹„ë˜ì—ˆìœ¼ë©°, PyTorchì™€ HuggingFace Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e695b355",
      "metadata": {
        "id": "e695b355"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets ipywidgets --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e94f83d",
      "metadata": {
        "id": "9e94f83d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import os\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        " # https://huggingface.co/gpt2-medium\n",
        "model_name = \"gpt2-medium\" # \"Qwen/Qwen3-0.6B\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
        "model.eval()\n",
        "\n",
        "log = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "433ba523",
      "metadata": {
        "id": "433ba523"
      },
      "outputs": [],
      "source": [
        "def generate_completion(prompt, max_new_tokens=50):\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(\n",
        "            input_ids,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            top_p=0.95,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "    output = tokenizer.decode(output_ids[0][input_ids.shape[-1]:], skip_special_tokens=True)\n",
        "    log.append({\"prompt\": prompt, \"response\": output})\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91e63227",
      "metadata": {
        "id": "91e63227"
      },
      "source": [
        "\n",
        "## ì‹¤ìŠµ ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
        "\n",
        "- 1) Zero-shot ë²ˆì—­ ì‹¤ìŠµ ì‹¤í–‰  \n",
        "- 2) Few-shot ë²ˆì—­ ì‹¤ìŠµ ì‹¤í–‰  \n",
        "- 3) ê°ì • ë¶„ì„ ì˜ˆì œ ì‹¤í–‰  \n",
        "- 4) ì‚¬ìš©ì ì§ì ‘ í”„ë¡¬í”„íŠ¸ ì‹¤ìŠµ  \n",
        "- 5) Chain-of-Thought ì˜ˆì œ ì‹¤í–‰  \n",
        "- 6) Tool-use ì˜ˆì œ ì‹¤í–‰  \n",
        "- ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41a96587",
      "metadata": {
        "id": "41a96587"
      },
      "outputs": [],
      "source": [
        "# zero-shotì€ demonstration x\n",
        "print(\"Zero-shot ì˜ˆì œ\")\n",
        "prompt = \"Translate English to French: I like pizza.\"\n",
        "print(\"Prompt:\", prompt)\n",
        "print(\"Generated:\", generate_completion(prompt))\n",
        "\n",
        "# few-shotì€ demonstration o\n",
        "print(\"\\n Few-shot ì˜ˆì œ\")\n",
        "few_shot = (\n",
        "    \"Translate English to French:\\n\"\n",
        "    \"English: Hello.\\nFrench: Bonjour.\\n\"\n",
        "    \"English: Good night.\\nFrench: Bonne nuit.\\n\"\n",
        "    \"English: I like pizza.\\nFrench:\"\n",
        ")\n",
        "print(\"Prompt:\\n\", few_shot)\n",
        "print(\"Generated:\", generate_completion(few_shot))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48b63c07",
      "metadata": {
        "id": "48b63c07"
      },
      "outputs": [],
      "source": [
        "# example 1: sentimental analysis\n",
        "print(\"\\n ê°ì • ë¶„ì„ Few-shot\")\n",
        "emotion_prompt = (\n",
        "    \"Tweet: I hate everything.\\nSentiment: Negative\\n\"\n",
        "    \"Tweet: I love sunshine.\\nSentiment: Positive\\n\"\n",
        "    \"Tweet: I want to cry.\\nSentiment:\"\n",
        ")\n",
        "print(generate_completion(emotion_prompt))\n",
        "\n",
        "# CoT example\n",
        "print(\"\\n Chain-of-Thought ì˜ˆì œ\")\n",
        "cot = (\n",
        "    \"Q: If a train has 5 cars and each car has 20 people, how many total people?\\n\"\n",
        "    \"A: Let's think step by step. Each car has 20 people. There are 5 cars. So 5 * 20 = 100. Answer: 100\"\n",
        "    \"\\n\\nQ: There are 3 boxes. Each box has 4 apples. How many apples?\\nA:\"\n",
        ")\n",
        "print(generate_completion(cot))\n",
        "\n",
        "# Tool use example\n",
        "print(\"\\n Tool-use ì˜ˆì œ\")\n",
        "tool_prompt = (\n",
        "    \"Question: What is 15 * 12?\\n\"\n",
        "    \"Let's use a calculator: 15 * 12 = 180.\\nAnswer: 180\\n\"\n",
        "    \"Question: What is 9 * 11?\\nLet's use a calculator:\"\n",
        ")\n",
        "print(generate_completion(tool_prompt))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73b0bec8",
      "metadata": {
        "id": "73b0bec8"
      },
      "outputs": [],
      "source": [
        "# With on your own prompts (PLAYGROUND)\n",
        "prompt_input = widgets.Textarea(\n",
        "    value='Input your prompt here...',\n",
        "    placeholder='Enter any instruction or query',\n",
        "    description='Prompt:',\n",
        "    layout=widgets.Layout(width='100%', height='100px')\n",
        ")\n",
        "button = widgets.Button(description='Generate')\n",
        "output = widgets.Output()\n",
        "\n",
        "@output.capture()\n",
        "def on_click(b):\n",
        "    output.clear_output()\n",
        "    prompt = prompt_input.value\n",
        "    result = generate_completion(prompt)\n",
        "    print(\"Generated:\", result)\n",
        "\n",
        "button.on_click(on_click)\n",
        "display(prompt_input, button, output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c78dc4c",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3c78dc4c"
      },
      "outputs": [],
      "source": [
        "# Output save files\n",
        "df = pd.DataFrame(log)\n",
        "df.to_csv(\"incontext_outputs.csv\", index=False)\n",
        "print(\"ğŸ’¾ Saved as incontext_outputs.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c40e4182",
      "metadata": {
        "id": "c40e4182"
      },
      "source": [
        "\n",
        "## ğŸ“ í€´ì¦ˆ (5ë¶„)\n",
        "\n",
        "1. Zero-shot learningê³¼ Few-shot learningì˜ ì°¨ì´ë¥¼ ì„œìˆ í•˜ì‹œì˜¤.  \n",
        "2. Chain-of-Thought promptingì´ ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ê°€?  \n",
        "3. Tool-use promptingì˜ í•œê³„ì ì€ ë¬´ì—‡ì¸ê°€?\n",
        "\n",
        "> ë‹µì•ˆì€ ì•„ë˜ ì…€ì— ì‘ì„±í•˜ì„¸ìš”.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaeac057",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eaeac057"
      },
      "outputs": [],
      "source": [
        "# ì—¬ê¸°ì— ì‘ì„±í•˜ì„¸ìš”.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BPmggjzZXVmn",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BPmggjzZXVmn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}