{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "23500204",
      "metadata": {
        "id": "23500204"
      },
      "source": [
        "\n",
        "# Parameter-Efficient Fine-Tuning (PEFT) ì‹¤ìŠµ\n",
        "**ì‘ì„±ì¼**: 2025-07-18 by Yeongtak Oh (Credit : DSAIL LAb, SNU)\n",
        "\n",
        "**ëª©í‘œ**:  \n",
        "- ì‚¬ì „ í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸ì— ëŒ€í•´ íš¨ìœ¨ì ì¸ íŒŒì¸íŠœë‹ ë°©ë²•ì¸ **LoRA (Low-Rank Adaptation)** ì´í•´  \n",
        "- HuggingFace `peft` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•œ ì‹¤ìŠµ  \n",
        "- Colabì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œ ì œê³µ  \n",
        "- ì˜ˆì œ ë°ì´í„°ì…‹: SST-2 (ê°ì • ë¶„ë¥˜)\n",
        "\n",
        "---\n",
        "\n",
        "> ë³¸ ë…¸íŠ¸ë¶ì€ HDí˜„ëŒ€ ì‹¤ìŠµì„ ìœ„í•´ êµìœ¡ìš© ìë£Œë¡œì„œ ì¤€ë¹„ë˜ì—ˆìœ¼ë©°, PEFTì˜ í•µì‹¬ ê°œë… ë° ì‹¤ìŠµì„ í¬í•¨í•©ë‹ˆë‹¤.  \n",
        "> **ì°¸ê³ :** ì´ ë…¸íŠ¸ë¶ì€ HuggingFace `transformers`, `datasets`, `peft` ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "351edb1d",
      "metadata": {
        "id": "351edb1d"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install transformers datasets peft accelerate bitsandbytes --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets transformers"
      ],
      "metadata": {
        "id": "-RTdYczpZtfH"
      },
      "id": "-RTdYczpZtfH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63b76dfc",
      "metadata": {
        "id": "63b76dfc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from datasets import load_dataset\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "import os\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"âœ… Using device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b337e454",
      "metadata": {
        "id": "b337e454"
      },
      "outputs": [],
      "source": [
        "# âœ³ï¸ ê¸°ë³¸ ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "base_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5de1b221",
      "metadata": {
        "id": "5de1b221"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "# âœ³ï¸ SST2 ë°ì´í„°ì…‹ ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
        "dataset = load_dataset(\"stanfordnlp/sst2\")\n",
        "\n",
        "def tokenize_fn(example):\n",
        "    return tokenizer(example[\"sentence\"], truncation=True, padding=\"max_length\", max_length=128)\n",
        "\n",
        "encoded = dataset.map(tokenize_fn, batched=True)\n",
        "encoded = encoded.remove_columns([\"sentence\", \"idx\"])\n",
        "encoded.set_format(\"torch\")\n",
        "print(encoded)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "sentences = list(dataset['train']['sentence'])"
      ],
      "metadata": {
        "id": "3Ds0GssFlF9a"
      },
      "id": "3Ds0GssFlF9a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\" \".join([s.strip() for s in sentences])"
      ],
      "metadata": {
        "id": "i0LfaPgnlMTt"
      },
      "id": "i0LfaPgnlMTt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db19685d",
      "metadata": {
        "id": "db19685d"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig\n",
        "\n",
        "# âœ³ï¸ LoRA ì„¤ì • ë° ëª¨ë¸ ë˜í•‘\n",
        "peft_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    inference_mode=False,\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    target_modules=[\"q_lin\", \"v_lin\"]  # DistilBERTìš©. ë˜ëŠ” [\"query\", \"value\"] ë“±\n",
        ")\n",
        "\n",
        "lora_model = get_peft_model(base_model, peft_config)\n",
        "lora_model.print_trainable_parameters()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "peft_config"
      ],
      "metadata": {
        "id": "yLrExC-zlVW4"
      },
      "id": "yLrExC-zlVW4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a9595ae",
      "metadata": {
        "id": "8a9595ae"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "# âœ³ï¸ í•™ìŠµ ì¸ì ì„¤ì •\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./lora_sst2\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=2e-4,\n",
        "    num_train_epochs=3,\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=lora_model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded[\"train\"].shuffle(seed=42).select(range(1000)),  # ìƒ˜í”Œ 1000ê°œ ì‚¬ìš©\n",
        "    eval_dataset=encoded[\"validation\"].select(range(300)),\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args"
      ],
      "metadata": {
        "id": "usnRmNIplZYO"
      },
      "id": "usnRmNIplZYO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.title('loss_plot')\n",
        "plt.xlabel('num of logging steps')\n",
        "plt.ylabel('training loss')\n",
        "plt.plot([trainer.state.log_history[i]['loss'] for i in range(len(trainer.state.log_history)-1)], label='LoRA loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "SDueAIvSkLbp"
      },
      "id": "SDueAIvSkLbp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bde8f7d",
      "metadata": {
        "id": "8bde8f7d"
      },
      "outputs": [],
      "source": [
        "# âœ³ï¸ í‰ê°€ ë° ì €ì¥\n",
        "metrics = trainer.evaluate()\n",
        "print(\"\\nğŸ“Š í‰ê°€ ê²°ê³¼:\", metrics)\n",
        "\n",
        "# LoRA adapterë§Œ ì €ì¥\n",
        "lora_model.save_pretrained(\"./lora_adapter_sst2\")\n",
        "print(\"ğŸ’¾ LoRA adapter ì €ì¥ ì™„ë£Œ: ./lora_adapter_sst2\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c2c9318",
      "metadata": {
        "id": "9c2c9318"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## ğŸ“Œ LoRAë€?\n",
        "\n",
        "LoRAëŠ” **Low-Rank Adaptation of Large Language Models**ì˜ ì¤„ì„ë§ë¡œ,  \n",
        "ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ëŠ” **ë™ê²°(freeze)** í•˜ê³ ,  \n",
        "ì¼ë¶€ ì¸µì— ëŒ€í•´ **low-rank í–‰ë ¬ì„ ì¶”ê°€ í•™ìŠµ**í•¨ìœ¼ë¡œì¨  \n",
        "**ë§¤ìš° ì ì€ ìˆ˜ì˜ í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°**ë¡œë„ fine-tuningì´ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.\n",
        "\n",
        "> ğŸ“ ì°¸ê³  ë¬¸í—Œ: [https://arxiv.org/abs/2106.09685](https://arxiv.org/abs/2106.09685)\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“Œ ì‹¤ìŠµ í•µì‹¬ í¬ì¸íŠ¸\n",
        "\n",
        "- `AutoModelForSequenceClassification`: ë¶„ë¥˜ìš© pre-trained ëª¨ë¸ ì‚¬ìš©  \n",
        "- `peft.LoraConfig`: íŒŒì¸íŠœë‹í•  ë ˆì´ì–´ ì„¤ì • (dropout, rank ë“±)  \n",
        "- `get_peft_model`: ê¸°ì¡´ ëª¨ë¸ì„ LoRA ì ìš© ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë˜í•‘  \n",
        "- **trainable parameters**ë§Œ ì¶œë ¥ í™•ì¸ â†’ ê¸°ì¡´ ëª¨ë¸ ëŒ€ë¹„ ì•½ 0.1~1% ìˆ˜ì¤€  \n",
        "- SST-2 ê°ì • ë¶„ë¥˜ ë°ì´í„°ì…‹ ì‚¬ìš© (ê¸ì •/ë¶€ì •)\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“Š ê²°ê³¼ í™•ì¸ ì˜ˆì‹œ\n",
        "\n",
        "- ì •í™•ë„(accuracy), ì†ì‹¤(loss) ë“± ê¸°ë³¸ í‰ê°€ ì§€í‘œ ì¶œë ¥  \n",
        "- `save_pretrained()` í˜¸ì¶œ ì‹œ full modelì´ ì•„ë‹ˆë¼ LoRA adapterë§Œ ì €ì¥ë¨  \n",
        "\n",
        "---  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bddc0b32",
      "metadata": {
        "id": "bddc0b32"
      },
      "source": [
        "\n",
        "## ğŸ“ í€´ì¦ˆ ë° ë³µìŠµ ì§ˆë¬¸\n",
        "\n",
        "1. LoRAì˜ í•µì‹¬ ì•„ì´ë””ì–´ëŠ” ë¬´ì—‡ì¸ê°€ìš”? ì–´ë–¤ ì¥ì ì´ ìˆë‚˜ìš”?  \n",
        "2. LoRAë¥¼ ì ìš©í•˜ê¸° ìœ„í•´ ì–´ë–¤ êµ¬ì„±ìš”ì†Œë“¤ì´ í•„ìš”í•œê°€ìš”?  \n",
        "3. Full fine-tuningê³¼ ë¹„êµí•´ PEFTì˜ ì œí•œì‚¬í•­ì€ ë¬´ì—‡ì´ ìˆì„ê¹Œìš”?\n",
        "\n",
        "> ì•„ë˜ ì…€ì— ììœ ë¡­ê²Œ ì‘ì„±í•´ ë³´ì„¸ìš”.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e27c185b",
      "metadata": {
        "id": "e27c185b"
      },
      "outputs": [],
      "source": [
        "# ì—¬ê¸°ì— ì‘ì„±í•˜ì„¸ìš”"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}