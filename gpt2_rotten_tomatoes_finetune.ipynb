{"cells":[{"cell_type":"markdown","id":"e29c2e0e","metadata":{"id":"e29c2e0e"},"source":["# Fine‑tuning GPT‑2 for Sentiment Analysis (rotten tomatoes)\n","\n","**작성일**: 2025-07-19 by Youngwoo Kimh (Credit : DSAIL Lab, SNU)\n","\n","**목표**:  \n","- BERT를 활용해 downstream task를 수행하는 실습\n","- Rotten tomato dataset을 통해 영화평의 긍정/부정을 파악\n","\n","---\n","> 본 노트북은 HD현대 실습을 위해 교육용 자료로서 준비되었으며, PyTorch와 HuggingFace Transformers 라이브러리를 사용합니다."]},{"cell_type":"markdown","id":"005a6546","metadata":{"id":"005a6546"},"source":["## 0. Setup"]},{"cell_type":"code","execution_count":null,"id":"b9e1803a","metadata":{"id":"b9e1803a"},"outputs":[],"source":["!pip -q install transformers datasets evaluate accelerate fsspec -U"]},{"cell_type":"markdown","id":"42aa5f14","metadata":{"id":"42aa5f14"},"source":["## 1. Imports"]},{"cell_type":"code","execution_count":null,"id":"00cb63df","metadata":{"id":"00cb63df"},"outputs":[],"source":["from datasets import load_dataset\n","from transformers import (GPT2TokenizerFast, GPT2ForSequenceClassification,\n","                          DataCollatorWithPadding, Trainer, TrainingArguments)\n","from peft import LoraConfig, get_peft_model\n","import evaluate, torch, numpy as np"]},{"cell_type":"markdown","id":"6f0fea5a","metadata":{"id":"6f0fea5a"},"source":["## 2. Load rotten tomatoes dataset"]},{"cell_type":"code","execution_count":null,"id":"a2ec779c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a2ec779c","outputId":"99e22f03-fa91-4882-b23b-a245b5e7f675","executionInfo":{"status":"ok","timestamp":1753062402905,"user_tz":-540,"elapsed":3956,"user":{"displayName":"­김영우 / 학생 / 협동과정 인공지능전공","userId":"15944929116565684190"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 8530\n","    })\n","    validation: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 1066\n","    })\n","    test: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 1066\n","    })\n","})\n"]}],"source":["# load rotten tomatoes dataset for sentiment analysis\n","raw = load_dataset(\"rotten_tomatoes\")\n","print(raw)"]},{"cell_type":"markdown","id":"74f7f050","metadata":{"id":"74f7f050"},"source":["### Inspect samples"]},{"cell_type":"code","execution_count":null,"id":"9c060ae5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9c060ae5","outputId":"7c1c0ee0-ba76-4bb4-ca3a-34fa8c2f22dd","executionInfo":{"status":"ok","timestamp":1753062402911,"user_tz":-540,"elapsed":4,"user":{"displayName":"­김영우 / 학생 / 협동과정 인공지능전공","userId":"15944929116565684190"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["LABEL: 1\n","the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\n","----------------------------------------\n","LABEL: 1\n","the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth .\n","----------------------------------------\n","LABEL: 1\n","effective but too-tepid biopic\n","----------------------------------------\n"]}],"source":["for i in range(3):\n","    print('LABEL:', raw['train'][i]['label'])\n","    print(raw['train'][i]['text'][:400])\n","    print('-'*40)"]},{"cell_type":"markdown","id":"242348d9","metadata":{"id":"242348d9"},"source":["## 3. Prepare Tokenizer and Tokenize dataset"]},{"cell_type":"code","execution_count":null,"id":"4fe2547a","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["feb917357947424cb29b4454e152de16","f16adb4e16e548c2a3d095e5d240c103","83fb8055282743b097b16d8348d01e5a","a27ea844999b4ea1ae205ef37da1132a","2a73143f68714688affb9e764f68ce16","1bd073474c4546ef8f44cb38ec6ad749","73f58ce354f04c54a59666884724c49f","3851c6bfb294474b82e6d7c578957a30","8a98538bd7014406b60d5453ee1e2376","6fb6469d41b04d8bb57065a18519be9a","7739b744ae924f1088c67ba0a6f3e0c0"]},"id":"4fe2547a","outputId":"99879453-65c9-4ecf-83c9-47c4a3aa6e43","executionInfo":{"status":"ok","timestamp":1753062404240,"user_tz":-540,"elapsed":1328,"user":{"displayName":"­김영우 / 학생 / 협동과정 인공지능전공","userId":"15944929116565684190"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"feb917357947424cb29b4454e152de16"}},"metadata":{}}],"source":["# load tokenizer and add padding token [PAD]\n","tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n","if tokenizer.pad_token is None:\n","    tokenizer.add_special_tokens({'pad_token':'[PAD]'})\n","\n","# tokenize all the sentences in the dataset\n","def tok(b): return tokenizer(b[\"text\"], truncation=True)\n","data = raw.map(tok, batched=True, remove_columns=[\"text\"]).rename_column(\"label\", \"labels\")\n"]},{"cell_type":"markdown","id":"e08e98bf","metadata":{"id":"e08e98bf"},"source":["### Load Model"]},{"cell_type":"code","execution_count":null,"id":"9e6318bb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9e6318bb","outputId":"bdebc35e-ecb6-44e3-d378-be00e0503adc","executionInfo":{"status":"ok","timestamp":1753062408704,"user_tz":-540,"elapsed":4463,"user":{"displayName":"­김영우 / 학생 / 협동과정 인공지능전공","userId":"15944929116565684190"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n","/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/layer.py:1803: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["PeftModel(\n","  (base_model): LoraModel(\n","    (model): GPT2ForSequenceClassification(\n","      (transformer): GPT2Model(\n","        (wte): Embedding(50258, 768)\n","        (wpe): Embedding(1024, 768)\n","        (drop): Dropout(p=0.1, inplace=False)\n","        (h): ModuleList(\n","          (0-11): 12 x GPT2Block(\n","            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPT2Attention(\n","              (c_attn): lora.Linear(\n","                (base_layer): Conv1D(nf=2304, nx=768)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=768, out_features=8, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=8, out_features=2304, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (c_proj): lora.Linear(\n","                (base_layer): Conv1D(nf=768, nx=768)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=768, out_features=8, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=8, out_features=768, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (mlp): GPT2MLP(\n","              (c_fc): Conv1D(nf=3072, nx=768)\n","              (c_proj): lora.Linear(\n","                (base_layer): Conv1D(nf=768, nx=3072)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=8, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=8, out_features=768, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (score): Linear(in_features=768, out_features=2, bias=False)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":6}],"source":["# load model for classification\n","model = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", num_labels=2)\n","\n","# resize token_embeddings length (added [PAD] token)\n","model.resize_token_embeddings(len(tokenizer))\n","\n","# define Lora(Low-rank adaptation) config\n","lora_cfg = LoraConfig(r=8, lora_alpha=16, target_modules=[\"c_attn\",\"c_proj\"])\n","\n","# get gpt-2 model with Lora adapted\n","model = get_peft_model(model, lora_cfg)\n","model.config.pad_token_id = tokenizer.pad_token_id\n","\n","# load model on gpu\n","model.to(\"cuda\")"]},{"cell_type":"markdown","id":"362b9660","metadata":{"id":"362b9660"},"source":["### Data collator"]},{"cell_type":"code","execution_count":null,"id":"2fabe0d7","metadata":{"id":"2fabe0d7"},"outputs":[],"source":["# define data collator (make dataset model-friendly)\n","collator = DataCollatorWithPadding(tokenizer)"]},{"cell_type":"markdown","id":"fca55104","metadata":{"id":"fca55104"},"source":["## 4. Training"]},{"cell_type":"code","execution_count":null,"id":"37a210ec","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":829},"id":"37a210ec","outputId":"55a5dfb0-f4d1-4dbf-b792-9ddedfe971fa","executionInfo":{"status":"ok","timestamp":1753062831390,"user_tz":-540,"elapsed":422683,"user":{"displayName":"­김영우 / 학생 / 협동과정 인공지능전공","userId":"15944929116565684190"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-8-716511285.py:14: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n","No label_names provided for model class `PeftModel`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1602' max='1602' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1602/1602 07:00, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.768300</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.693500</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.674400</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.614000</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.568900</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.509100</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.456500</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.452500</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.462000</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.433300</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.431600</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.432300</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.434600</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.387600</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.449000</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.403500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=1602, training_loss=0.5103202438384258, metrics={'train_runtime': 421.7756, 'train_samples_per_second': 60.672, 'train_steps_per_second': 3.798, 'total_flos': 533981440770048.0, 'train_loss': 0.5103202438384258, 'epoch': 3.0})"]},"metadata":{},"execution_count":8}],"source":["# define metrics to select the best model while training\n","metric = evaluate.load(\"accuracy\")\n","def acc(p): logits, labels = p; return metric.compute(predictions=np.argmax(logits, -1), references=labels)\n","\n","# define training arguments\n","args = TrainingArguments(\n","    \"gpt2-rt-sentiment\",\n","    per_device_train_batch_size=4, # batch size for each gpu\n","    gradient_accumulation_steps=4, # the number of batches to update model simultaneously\n","    num_train_epochs=3, # total epochs\n","    logging_steps=100,\n","    fp16=True, # cast model precision to fp16 (half the memory compared to original fp32 model)\n","    report_to=\"none\",\n",")\n","\n","# define trainer class\n","trainer = Trainer(\n","    model=model,\n","    args=args,\n","    train_dataset=data[\"train\"], # training dataset\n","    eval_dataset=data[\"validation\"], # evaluation dataset\n","    tokenizer=tokenizer,\n","    data_collator=DataCollatorWithPadding(tokenizer, pad_to_multiple_of=8),\n","    compute_metrics=acc,\n",")\n","trainer.train()"]},{"cell_type":"markdown","id":"5ca4374e","metadata":{"id":"5ca4374e"},"source":["## 5. Evaluation"]},{"cell_type":"code","execution_count":null,"id":"33cb8eb2","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":108},"id":"33cb8eb2","outputId":"4a47c858-a5ad-40e6-da24-59e1d67eea24","executionInfo":{"status":"ok","timestamp":1753062835062,"user_tz":-540,"elapsed":3668,"user":{"displayName":"­김영우 / 학생 / 협동과정 인공지능전공","userId":"15944929116565684190"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='134' max='134' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [134/134 00:03]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_runtime': 3.6596,\n"," 'eval_samples_per_second': 291.285,\n"," 'eval_steps_per_second': 36.616,\n"," 'epoch': 3.0}"]},"metadata":{},"execution_count":9}],"source":["trainer.evaluate()"]},{"cell_type":"markdown","id":"61cbb50d","metadata":{"id":"61cbb50d"},"source":["## 6. Inference demo"]},{"cell_type":"code","execution_count":null,"id":"6455b345","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6455b345","outputId":"123d8090-8ce7-4890-fa08-a64a138ecbbe","executionInfo":{"status":"ok","timestamp":1753062835141,"user_tz":-540,"elapsed":76,"user":{"displayName":"­김영우 / 학생 / 협동과정 인공지능전공","userId":"15944929116565684190"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["An amazing movie with stellar performances. → POSITIVE\n","It was a waste of two hours. → NEGATIVE\n"]}],"source":["\n","def predict(text):\n","    # tokenize input\n","    inputs = tokenizer(text, return_tensors='pt').to('cuda')\n","\n","    # inference\n","    with torch.no_grad():\n","        logits = model(**inputs).logits\n","\n","    # probability of each label (Positive, Negative)\n","    label = logits.argmax(-1).item()\n","    return 'POSITIVE' if label==1 else 'NEGATIVE'\n","\n","# example sentence\n","examples = [\n","    'An amazing movie with stellar performances.',\n","    'It was a waste of two hours.'\n","]\n","\n","for ex in examples:\n","    print(ex, '→', predict(ex))\n"]},{"cell_type":"code","source":["review = '' # fill your review sentence\n","print(review, '→', predict(review))"],"metadata":{"id":"rCYQtMc7ppsJ"},"id":"rCYQtMc7ppsJ","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"feb917357947424cb29b4454e152de16":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f16adb4e16e548c2a3d095e5d240c103","IPY_MODEL_83fb8055282743b097b16d8348d01e5a","IPY_MODEL_a27ea844999b4ea1ae205ef37da1132a"],"layout":"IPY_MODEL_2a73143f68714688affb9e764f68ce16"}},"f16adb4e16e548c2a3d095e5d240c103":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1bd073474c4546ef8f44cb38ec6ad749","placeholder":"​","style":"IPY_MODEL_73f58ce354f04c54a59666884724c49f","value":"Map: 100%"}},"83fb8055282743b097b16d8348d01e5a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3851c6bfb294474b82e6d7c578957a30","max":1066,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8a98538bd7014406b60d5453ee1e2376","value":1066}},"a27ea844999b4ea1ae205ef37da1132a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fb6469d41b04d8bb57065a18519be9a","placeholder":"​","style":"IPY_MODEL_7739b744ae924f1088c67ba0a6f3e0c0","value":" 1066/1066 [00:00&lt;00:00, 3772.26 examples/s]"}},"2a73143f68714688affb9e764f68ce16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1bd073474c4546ef8f44cb38ec6ad749":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73f58ce354f04c54a59666884724c49f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3851c6bfb294474b82e6d7c578957a30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a98538bd7014406b60d5453ee1e2376":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6fb6469d41b04d8bb57065a18519be9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7739b744ae924f1088c67ba0a6f3e0c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}